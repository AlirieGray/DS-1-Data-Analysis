{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src='img/ms_logo.jpeg' height=40% width=40%></center>\n",
    "\n",
    "<center><h1>Outlier Detection, Sample Size, and Confidence Intervals</h1></center>\n",
    "\n",
    "When you're designing an experiment, numbers matter.  After all, we want out experiments to be statistically valid--otherwise, we're just guessing.  In this notebook, we'll learn a method for detecting outliers in our data set called \"Tukey Fences\", named after famed statistician John Tukey.  \n",
    "\n",
    "Next, we'll learn about confidence inteverals, sample size, and the relationship between the two.  We'll learn how to calculate confidence intervals based on sample size, as well as how to determine the minimum sample size needed in order to reach a specific confidence interval.  \n",
    "\n",
    "Let's get started!\n",
    "\n",
    "<center><h2>Outlier Detection</h2></center>\n",
    "\n",
    "Recall that before we begin an experiment, we usually start by \"cleaning\" our dataset.  This step usually includes things like:\n",
    "\n",
    "* Exploring our dataset(s) to get a feel for what changes need to be made to make it more usable\n",
    "* Examining and standardizing the values within cells (converting \"yes\"/\"no\" answers to 1's and 0's, for example)\n",
    "* Dealing with cells that contain NaNs (Null values)\n",
    "* Organizing and structuring datasets as needed (for instance, combining many small datasets into one big one)\n",
    "* Normalizing continuous data into z-scores with a mean of 0 and unit variance.  \n",
    "\n",
    "Another major step we need to do at this point in the project is to detect **outliers**, and determine how to deal wit them.  Outliers are extreme values that can skew our dataset, sometimes giving us an incorrect picture of how things actually are in our dataset.  The hardest part of this is determining which data points are acceptable, and which ones constitute \"outlier\" status.  This is where \"Tukey Fences\" come into play!\n",
    "\n",
    "### 1.5 x IQR\n",
    "\n",
    "In order to find outliers, we first need a working definition of what constitutes an outlier.  Tukey suggested we calculate the range between the first quartile (25%) and  third quartile (75%) in the data, called the **interquartile range**.  We then multiply this value by 1.5.  To get the Fence for high values, add this value to the Q3 value.  Anything greater than this \"Fence\" value is considered an outlier.  Similarly, to get the Fence for low values, subtract 1.5 x IQR from Q1.  Anything less than this \"Fence\" value is also considered an outlier.  \n",
    "\n",
    "Let's try an example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(1547)\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1100.000000\n",
       "mean      101.190110\n",
       "std        17.605682\n",
       "min        10.235233\n",
       "25%        94.658860\n",
       "50%       100.340004\n",
       "75%       106.459821\n",
       "max       195.226466\n",
       "dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a random normal distribution of 1000 samples with mean 100 and std_dev of 8\n",
    "normal_dist = np.random.normal(100, 8, (1000)).astype('float64')\n",
    "# Generate a random uniform distribution between 1 and 200 with 100 samples\n",
    "uniform_dist = np.random.uniform(1, 200, (100)).astype('float64')\n",
    "# Combine both distributions and store in and Pandas Series object\n",
    "sample_dset = pd.Series(np.append(normal_dist, uniform_dist))\n",
    "sample_dset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've created an ugly data set, let's see if we can identify some outliers.  \n",
    "\n",
    "Start by calculating the **Inter-Quartile Range**: Q3 - Q1.\n",
    "\n",
    "Next, calculate how far your fences are from the quartiles: f = IQR x 1.5\n",
    "\n",
    "Finally, place your fences and filter for values outside them:  Lower Fence = Q1 - f, Upper Fence = Q3 + f\n",
    "\n",
    "See if you can write write some code to filter for outliers in the `sample_dset` array we've just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Locations for Q1 and Q3\n",
    "q1 = None\n",
    "q3 = None\n",
    "\n",
    "# calculate fence locations\n",
    "lower_fence = None\n",
    "upper_fence = None\n",
    "\n",
    "# Filter out the outliers and inspect them!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! That works, but it isn't efficient to calculate this manually every time we run across a new data set.  \n",
    "\n",
    "**TASK:** Write a function that takes in a pandas series, and returns a new pandas series with the outliers removed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(series):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Sample Size and Confidence Intervals</h2></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MS-ML-P3]",
   "language": "python",
   "name": "conda-env-MS-ML-P3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
